# Data Structure 면접 질문 리스트
* **해시 테이블(Hash Table)과 시간 복잡도에 대해 설명해주세요.**
  * 해시테이블은 임의의 길이를 갖는 임의의 데이터를 고정된 길이의 데이터로 매핑하는 단방향 함수인 해시함수를 사용하여 키를 해시 값으로 매핑하고, <br/>
    이 해시 값을 색인 또는 주소 삼아 value를 key와 함께 저장하는 자료구조이다.
  * 시간복잡도란 입력값의 변화에 따라 연산 수행 시, 입력값과 연산 수행 시간의 상관관계을 나타내는 척도로 시간복잡도와 로직의 수행시간은 비례. <br/>
    입력값이 커짐에 따라 증가하는 시간의 비율을 최소화한 알고리즘의 효율적인 알고리즘이다. (연산 횟수에 비해 걸리는 시간의 비율을 계산한 값)
  * 해시테이블은 key-value가 1:1로 매핑되어 있어 삽입, 삭제, 검색 모두 평균적으로 O(1)의 시간복잡도를 가짐.
  * but! 해시 충돌 발생 시엔, Chanining에 연결된 리스트까지 검색해야 하므로 O(N)까지 증가 가넝..
<br/>    

* **해시 충돌이 발생하는 이유와 충돌 해결 전략(예: 체이닝, 개방 주소법)에 대해서 간략히 설명해주세요.**
  * 이유
    * 순서에 상관없이 Key만을 가지고 연산을 하기 때문에 순서가 있는 배열에 어울리지 않아 발생 가능ㅇㅇ
    * 데이터가 저장되기 전에 미리 저장공간을 확보해야해서 공간 효율성이 떨어져 공간 부족 or 아예 채워지지않는 경우 발생 ㅇㅇ
    * 해시 함수 의존도가 높아 함수가 복잡해 연산이 오래걸리면 해시테이블의 연산 속도도 증가해 시간복잡도도 변화
  * 체이닝
    * 충돌 발생 시 기존값과 새로운값을 같이 저장하는 방식
    * 연결리스트 사용 방식
      * 각각의 버킷들을 연결리스트로 만들어 Clollision발생하면 해당 bucket의 list에 추가하는 방식
      * 데이터 개수가 적을 때 사용. 메모리 측면에서
      * 연결리스트의 특징대로 간단한 삭제 또는 삽입 가능
      * but, 작은 데이터들 저장할 땐 연결리스트 자체의 오버헤드가 부담이 된다.
    * 트리 사용 방식
      * 하나의 해시 버킷에 할당된 key-value쌍의 개수가 많을 때 사용 - 트리는 기본적으로 메모리 사용량이 많아서
    * 체이닝 방식은 충돌이 발생해도 그냥 저장해주기 때문에 미리 많은 공간을 확보해야 할 필요 X
    * but, 한 해시 값에 자료들이 많이 연결되면 검색 효율이 떨어지고 리스트 및 트리 저장 위해 외부 저장 공간을 사용하고 추가로 관리해줘야 함
  * 개방주소법
    * 충돌 발생 시, 빈 방을 찾아 값 저장
    * 빈 방 탐색법 : 선형 탐색, 제곱 탐색, 이중 해싱 통해서..!
<br/>

* **힙과 시간 복잡도에 대해 설명해주세요.**
  * 힙은 여러 개의 값 중 가장 크거나 작은 값을 빠르게 찾기 위해 고안된 완전 이진 트리
  * 부모의 값은 항상 자식의 값보다 크거나 작아야하는 규칙 때문에 루트 노드에는 항상 가장 큰 값 혹은 작은 값이 저장되어있어 최댓값과 최솟값을 O(1)안에 찾기 가능
  * 삽입과 삭제는 모두 O(log N) - 자체는 O(1)이지만 재정렬하는 과정에서 O(log N) 소요
<br/>

* **(최대 힙, 최소 힙에 대한 상황이 주어지고) 삽입과 삭제 시 어떻게 진행되나요?. (그림이 있을 때 설명 가능하도록 연습하시면 좋을 것 같습니다!)(우선순위를 정하고, 트리의 부모-자식에 대한 swap이 일어나는 과정을 잘 설명할 줄 알아야 한다.)**
  * 삽입
    * 힙에 새로운 요소 들어오면 일단 힙의 마지막 노드에 삽입
    * 새로운 노드를 부모 노드들과 교환(스왑)
    * 규칙에 맞으면 그대로, 위배하면 부모 노드와 교환 - 이 과정을 규칙에 맞을 때까지 반복!
  * 삭제
    * 루트 노드 제거하고 그 자리에 가장 마지막 노드 삽입
    * 올라간 노드와 그의 자식 노드들을 비교
    * 조건 만족 시 그대로 두고 아니면 자식과 교환 - 조건 만족할 때까지 이 과정 반복!
      * 최대 힙
        * 부모보다 더 큰 자식이 하나만 있으면 그 자식과 부모 스왑, 둘이 있으면 자식들 중 큰 값과 부모 스왑
        * 부모보다 더 큰 자식 없으면 교환하지 않고 종료
      * 최소 힙
        * 부모보다 더 작은 자식이 하나만 있으면 그 자식과 부모 스왑, 둘 있으면 자식들 중 작은 값과 부모 스왑
        * 부모보다 더 작은 자식이 없으면 교환하지 않고 종료
  <br/>
  
* **ArrayList(배열)와 LinkedList(연결 리스트)의 차이점과 둘의 장단점에 대해 설명해주시고, 어떤 상황에 각 자료구조를 사용하는 것이 적절한지 이유와 함께 설명해주세요.**
  * ArrayList - 연속적
    * 탐색은 빠르게 할 수 있지만, 삽입과 삭제는 비교적 느리다는 단점 존재
    * 연속적으로 메모리 상에 존재하기 때문에 배열 시작 주소와 index를 이용하여 원하는 원소에 빠르게 접근 가능함 - 순차적인 삽입과 삭제는 더 빠르기에 이 경우에 이거 사용
    * BUT 빈번한 배열 복사로 비효율적인 메모리 사용
  * LinkedList - 불연속적
    * 삽입과 삭제는 빠르지만, 탐색은 느림
    * 불연속적으로 위치한 각 원소들이 연결된 것이기에 처음부터 따라가야만 원하는 원소에 접근 가능 데이터가 많아질수록 접근성이 떨어짐
    * 각 요소 간 연결반 변경해주면 되기 때문에 처리 속도가 빠르기에 (비순차적인) 중간 데이터를 삽입 및 삭제하는 경우에 사용
<br/>

* **스택과 큐의 특징을 간략히 설명해주시고, 만약 직접 스택과 큐를 구현해야 한다면 저장 공간으로 어떤 자료구조를 사용할 것인지 이유와 함께 설명해주세요.**
  * 스택
    * 마지막에 들어간 데이터를 먼저 꺼내는 후입선출 LIFO 구조
    * 주로 문서 작업 시에 undo, redo 기능 구현과 웹브라우저 방문 기록 관리할 때 활용됨
  * 큐
    * 먼저 들어간 데이터를 먼저 꺼내는 선입선출 FIFO 구조
    * 연결리스트 사용하는 것이 효율적
    * 큐를 통해 데이터가 줄지어 순서대로 처리되기 때문에 BFS 또는 컴퓨터 버퍼에서 주로 활용
  * 나는 큐 사용 ! 데이터를 순서대로 넣고 순서대로 꺼내는 것이 좋음 + Priority Queue사용 시엔 우선순위에 따라 데이터를 꺼낼 수 있어 더 효율적 같음
<br/>

* **그래프 구현법 2가지에 대해 설멍해주세요. 그리고 두 방법의 장단점에 대해 비교해주세요**
  * 2차원 배열을 통한 인접 행렬
    * 그래프의 노드를 2차원 배열로 만든 것으로 각 정점 연결 정보를 0과 1로 표현
    * 장점 : 배열의 위치를 확인하여 두 정점의 연결 정보 탐색 시 O(1)의 시간복잡도 / 비교적 간단한 구현
    * 단점 : 인접 행렬 생성 시엔 O(N^2)의 시간복잡도 소요 / 무조건 2차원 배열이 필요해서 메모리 낭비 심함
  * 연결리스트를 통한 인접 리스트
    * 그래프의 노드를 연결 리스트로 표현한 것으로 주로 정점의 연결 리스트 배열을 통해 관계를 설정하여 구현
    * 장점 : 정점들의 연결 정보 탐색할 때 O(n)의 시간복잡도 / 필요한 공간만 사용하여 저장 공간 낭비 적음
    * 단점 : 특정 두 정점의 연결 여부 탐색 시 오랜 시간 소요 - 리스트가 탐색 속도가 느려서 / 비교적 어려운 구현
<br/>

* **트리 탐색법 2가지 중 1개에 대해 설명해주시고 어느 상황에서 사용하는 것이 적절한지 설명해주세요.**
  * BFS (너비 우선 탐색)
    * 레벨 순회 방식으로 인접한 노드들부터 차례대로 방문해 트리 전체 탐색하는 구현법
    * 트리의 가장 낮은 레벨+왼쪽의 노드부터 순서대로 방문
    * 큐 자료구조 활용 시 구현에 편리
    * 가중치가 모든 같은(경로의 특징 저장 못함) 그래프에서 최단거리를 찾을 때 활용 (깊이를 계산해야하는 최단 경로의 길이 == 깊이)
      * 현재 노드에서 가장 가까운 곳부터 찾기 때문에 경로 탐색 시 첫번째로 찾은 해답이 곧 최단거리임! (DFS는 아님)
  * DFS(깊이 우선 탐색)
    * 재귀적인 특징과 백트래킹을 이용한 모든 경우를 하나하나 다 탐색하는 완전 탐색 문제 - 순열 및 조합
    * 정점과 간선의 개수가 많아 검색 대상 그래프가 큰 경우
    * 경로의 특징을 저장해둬야 하는 문제
<br/>

* **시간복잡도가 O(n^2)인 정렬 알고리즘 중 하나에 대해 설명해주세요**
  * 버블 정렬
    * 인접한 두 수를 비교하여 정렬해나가는 방법.
    * 작은 숫자는 왼쪽으로, 큰 숫자는 오른쪽으로 이동!
    * 정렬을 1회전 수행할 때마다 정렬에서 제외되는 데이터가 하나씩 늘어남
    * 장점 : 구현 매우 간단
    * 단점 : 순서에 맞지 않는 요소를 인접한 요소와 교환. 특정 요소가 최종 정렬 위치에 있어도 교환되는 일 발생
    * 자료의 교환 작업(SWAP)이 자료의 이동 작업(MOVE)보다 더 복잡하기 때문에 버블 정렬은 단순성에도 불구하고 거의 쓰이지 않음..!
<br/>

* **시간복잡도가 O(nlogn)인 정렬 알고리즘 중 하나에 대해 설명해주세요**
  * 퀵 정렬
    * 기준이 되는 pivot값 정한 후 pivot 기준으로 분할 및 정렬
    * 리스트 안에 있는 한 요소 선택 = pivot
    * 피벗을 기준으로 피벗보다 작은 요소들은 왼쪽, 큰 요소들은 오른쪽으로 옮겨짐
    * 피벗 제외하고 각각 왼쪽과 오른쪽 리스트 재정렬 (이때 순환호출 이용하여 정렬 반복. 부분리스트도 피벗정하고 어쩌구 반복)
    * 리스트의 크기가 0이나 1이 될 때까지 즉, 부분 리스트들의 더 이상 분할이 불가능할 때까지 반복
    * 장점
      * 빠른 속도. 시간복잡도가 동일한 다른 정렬 알고리즘과 비교했을 때도 가장 빠름..!
      * 추가 메모리 공간 필요X 딱 O(log n)만큼의 메모리를 필요로 함
    * 단점
      * 이미 정렬된 리스트에서는 퀵 정렬의 불균형 분할에 의해 오히려 수행시간이 더 길어짐
      * => 방지하기 위해 데이터 중 크기순으로 중간 값을 피벗으로 정하는 등 피벗 선택 시 리스트를 최대한 균등하게 분할할 수 있는 데이터를 선택!!
    *  퀵 정렬이 불필요한 데이터의 이동을 줄이고 먼 거리의 데이터를 교환할 뿐만 아니라, 한 번 결정된 피벗들이 추후 연산에서 제외되는 특성 때문..!
<br/>
