## 운영체제 면접 질문 리스트

<details>
    <summary>프로그램, 프로세스, 스레드의 차이에 대해 설명해주세요.</summary>
    <br/><code>코드 파일</code>, <code>자원 할당 단위</code>, <code>동시적 흐름</code><br/><br/>

    프로그램은 어떤 작업을 하기 위한 명령어의 집합으로 저장 장치에는 존재하지만 메모리에는 올라가 있지 않은 정적인 상태를 의미합니다.
    프로세스는 프로그램 실행 시 운영체제로부터 자원을 할당받은 작업의 단위입니다.
    스레드는 하나의 프로세스 내에서 동시에 진행되는 흐름의 단위로 한 프로세스 내의 여러 스레드들은 동시에 실행될 수 있습니다.

</details>

<details>
    <summary>멀티프로세스와 멀티스레드의 특징에 대해 설명해주세요.</summary>
    <br/><code>하나의 프로그램에서 여러 프로세스</code>, <code>하나의 프로세스에서 여러 스레드</code><br/><br/>

    멀티 프로세스는 하나의 프로그램에서 여러 프로세스를 실행하는 것으로 각 프로세스가 독립적으로 실행되어 프로세스 하나에 문제가 발생해도 나머지 프로세스는 정상적으로 실행될 수 있습니다. 그러나 각 프로세스는 독립된 자원을 할당받아 실행되기 때문에 프로세스 사이에 공유하는 메모리가 없어 컨텍스트 스위칭에 대한 오버헤드가 발생합니다.

    멀티 스레드는 하나의 프로세스에서 여러 스레드를 실행하는 것으로 이 경우 하나의 프로그램에서 두 가지 이상의 동작을 동시에 처리하는 것이 가능해집니다.
    하나의 프로세스 내에서 실행되기 때문에 프로세스를 생성하고 자원을 할당하는 시스템 콜이 줄어 자원을 효율적으로 관리할 수 있습니다. 또한 스레드는 프로세스 내 메모리를 공유하기 때문에 스레드 간 데이터를 주고 받는 것이 간단해져 스레드 간 컨텍스트 스위칭에 대한 오버헤드가 줄어듭니다.
    그러나 스레드 간 자원을 공유하기 때문에 동기화 문제가 발생할 수 있으며 하나의 스레드에 문제가 발생해도 전체 프로세스에 영향을 미칠 수 있다는 문제점이 있습니다.

</details>

<hr/>

<details>
    <summary>프로세스의 주소공간은 어떻게 구성되어있는지 설명해주세요.</summary>
    <br/><code>코드</code>, <code>데이터</code>, <code>힙</code>, <code>스택</code><br/><br/>

    먼저 프로세스 주소공간은 프로세스가 할당받은 메모리를 효율적으로 관리하기 위해 구성된 메모리 구조로 코드, 데이터, 힙, 스택 영역으로 이루어져 있습니다. 코드 영역은 CPU가 실행할 수 있는 기계어로 변환된 프로그램 코드가 저장되며 프로그램 실행 도중 수정될 수 없는 Read-Only 영역입니다. 같은 프로그램에서 실행된 여러 프로세스는 코드 영역을 공유하여 메모리를 효율적으로 사용할 수 있습니다.
    다음으로 데이터 영역은 초기화된 전역 변수, static 변수들이 저장되며 프로그램 실행 중 변수가 수정될 수 있는 Read-Write 영역입니다. 이 영역은 프로그램 실행 시 생성되고 종료 시에 소멸됩니다.
    힙 영역은 프로그램 실행 중에 동적으로 할당되어 런타임에 메모리의 크기가 결정되는 영역으로 주로 객체와 같은 참조형 데이터가 저장됩니다. 사용자에 의해 메모리 공간이 동적으로 할당되고 해제되어 사용 가능한 메모리 공간이 조각나있는 메모리 파편화 문제가 발생할 수 있습니다. (낮은 주소 → 높은 주소)
    마지막으로 스택 영역은 지역 변수나 매개 변수가 저장되는 공간으로 함수 호출 시마다 스택 프레임이 쌓입니다. 즉 함수 호출과 함께 메모리가 할당되고 함수 종료 시 소멸됩니다. 따라서 재귀 함수가 너무 깊게 호출되거나 선언된 지역 변수가 너무 많아 스택 영역을 초과하게 되면 stack overflow 에러가 발생할 수 있습니다. (높은 주소 → 낮은 주소)

    한 프로세스 내에 여러 스레드들은 스택을 제외한 코드, 데이터, 힙 영역을 공유하여 메모리를 효율적으로 사용할 수 있습니다.

</details>

<details>
    <summary>프로세스의 주소공간에서 왜 Stack 부분과 Data 부분을 나누어서 구성했는지 설명해주세요.</summary>
    <br/><code>메모리 할당 주기</code>, <code>접근 제한</code><br/><br/>

    스택은 상단 부분에서만 데이터의 추가와 삭제가 발생하는 자료구조로 데이터 삭제는 가장 최근에 추가된 데이터에 대해서만 가능합니다. 이는 함수의 호출 및 종료에 적합한 자료구조로 예를 들어 a, b, c 순서대로 함수가 호출되면 관련 스택 프레임이 a, b, c 순서대로 저장되어 함수 종료는 c, b, a의 순서로 진행될 수 있습니다. 또한 지역 변수, 매개 변수 등의 메모리 공간은 프로그램 실행부터 종료까지 할당해줄 필요 없이 해당 함수가 호출되었을 때에만 메모리를 할당하여 메모리를 보다 효율적으로 사용할 수 있게 됩니다.

    스택에 저장된 변수는 호출된 함수 내에서만 접근이 가능한 반면 전역 변수나 정적 변수는 어떤 함수에서도 접근이 가능하여 별도의 데이터 영역이 필요해지게 되었습니다. 또한 전역 변수, 정적 변수는 프로그램 실행부터 종료까지 살아있으므로 메모리 할당 주기가 같은 데이터 영역에 저장해야 합니다.

</details>

<details>
    <summary>프로세스의 주소공간에서 stack과 heap을 메모리 접근과 관리 측면에서 비교해주세요.</summary>
    <br/><code>접근 속도</code>, <code>메모리 할당/해제</code>, <code>메모리 접근 제한</code>, <code>메모리 파편화</code><br/><br/>

    스택은 매우 빠른 액세스가 가능한 반면 힙은 상대적으로 접근 속도가 느립니다.
    스택은 명시적으로 메모리를 할당 및 해제할 필요가 없지만 힙은 사용자가 명시적으로 할당 및 해제해야 하므로 메모리를 관리할 별도의 책임이 발생합니다.
    스택 영역의 데이터는 현재 호출된 함수 내에서만 접근이 가능한 반면 힙의 데이터는 메모리가 해제되기 전까지는 전역적으로 접근이 가능합니다.
    스택은 함수 호출 시 메모리가 할당되고 함수 종료 시 소멸하는 식으로 CPU에 의해 효율적으로 관리되는 반면 힙은 사용자가 직접 할당, 해제하므로 사용 가능한 메모리 공간이 조각나있는 메모리 파편화 문제가 발생할 수 있습니다.

</details>

<details>
    <summary>PCB가 Context Switching 과정에서 왜 필요한지 말씀해주세요.</summary>
    <br/><code>프로세스 관련 정보 임시 저장소</code><br/><br/>

    현재 작업 중인 프로세스에 할당된 CPU를 I/O 요청, 타임 퀀텀 초과 등의 이유로 다른 프로세스에 할당하기 위해서는 컨텍스트 스위칭이라는 일련의 작업이 필요하게 됩니다. 즉 현재 작업 중인 프로세스에 관련된 정보를 저장해두고 다음으로 실행할 프로세스에 관한 정보들을 CPU의 캐시에 적재하는 과정이 이루어지는데요. 이때 프로세스 상태, 프로세스 ID 등 프로세스 관련 정보들을 저장하기 위한 공간으로 process control block, 즉 PCB를 사용하게 됩니다. 정리하자면 컨텍스트 스위칭에서 기존 프로세스 상태를 PCB에 저장하여 다른 프로세스 수행 후 다시 해당 프로세스를 재수행할 때 이전 작업을 이어서 할 수 있도록 하기 위해 PCB가 필요한 것입니다.

</details>

<details>
    <summary>Context Switching은 언제 발생하는지 말씀해주세요.</summary>
    <br/><code>running → waiting 상태</code>, <code>terminated 상태</code>, <code>quantum time 초과</code><br/><br/>

    일단 현재 CPU가 실행 중인 프로세스를 다른 프로세스로 바꾸기 위해 컨텍스트 스위칭이 발생하는데요. CPU가 다른 프로세스로 실행 대상을 바꿔야 하는 상황에는 여러 가지가 있습니다. 먼저 현재 실행 중인 프로세스에 I/O 요청이 발생하게 되면 CPU는 idle 상태 즉 아무것도 하지 않게 됩니다. CPU는 매우 비싼 자원으로 이런 놀고 있는 CPU를 다른 준비 상태의 프로세스에 할당하여야 합니다. 따라서 실행할 프로세스를 바꾸는 컨텍스트 스위칭이 발생합니다. 마찬가지의 이유로 현재 프로세스의 작업이 끝난 이후 idle 상태가 된 CPU가 새로운 프로세스를 실행시키기 위해 컨텍스트 스위칭이 발생합니다. 이 외에도 라운드 로빈 방식의 CPU 스케줄링을 하는 운영체제에서 현재 프로세스의 작업 시간이 정해진 퀀텀 타임을 초과한 경우 컨텍스트 스위칭이 발생할 수 있습니다.

</details>

<details>
    <summary>CPU 스케줄링이 발생하는 시기에 대해 CPU 반납 방식과 관련하여 설명해주세요.</summary>
    <br/><code>선점형 스케줄링</code>, <code>비선점형 스케줄링</code><br/><br/>

    현재 프로세스에 할당된 CPU를 다른 프로세스에 할당하는 것이 여러 가지 이유에서 합당할 때 CPU 스케줄링이 발생하는데요. 이 이유에 따라 프로세스가 자율적으로 CPU를 반납할 수도 운영체제에 의해 CPU를 회수당할 수도 있습니다.

    먼저 현재 프로세스에 I/O 요청이 발생하거나 프로세스가 종료되면 CPU를 자율적으로 반납합니다. 이 경우 idle 상태가 된 CPU를 놀게 하는 것보다 다른 준비 상태의 프로세스를 실행시킴으로써 시스템 자원을 효율적으로 사용할 수 있습니다. 반면 높은 우선순위의 새로운 프로세스가 나타나거나 현재 프로세스의 작업 시간이 정해진 시간을 초과한 경우에는 운영체제에 의해 CPU를 강제로 회수당하게 됩니다.

    이렇게 CPU를 반납하는 방식이 자율적인가 타율적인가에 따라 CPU 스케줄링을 선점형, 비선점형으로 분류할 수 있습니다. 선점형 스케줄링은 실행 중인 작업이 끝나지 않았더라도 운영체제에 의해 강제로 CPU 사용권을 빼앗기는 방식으로 모든 프로세스는 일정 시간 동안만 CPU를 점유할 수 있습니다. 반면 비선점형 스케줄링은 실행 중인 작업이 끝나야만 CPU 사용권을 넘겨주는 방식으로 실행 중인 프로세스가 자율적으로 CPU를 반납할 때까지 CPU를 계속 점유하게 됩니다.

</details>

<details>
    <summary>여러 CPU 스케줄링 알고리즘 중 1개를 선택하여 자세히 설명해주세요.</summary>
    <br/><code>FCFS</code>, <code>SJF</code>, <code>SRTF</code>, <code>Priority</code>, <code>RR</code>, <code>MQ</code>, <code>MFQ</code><br/><br/>

</details>

<details>
    <summary>인터럽트가 무엇인지, 왜 사용하는지 설명해주세요.</summary>
    <br/><code>CPU 자원의 효율적 이용</code>, <code>예외 처리의 효율화</code>, <code>응답성 향상</code>, <code>정확한 타이밍 제어</code><br/><br/>

    인터럽트는 CPU의 즉각적인 처리를 필요로 하는 이벤트나 예외 상황을 알리기 위한 주변 하드웨어나 소프트웨어로부터의 요청을 말합니다.
    입출력 장치는 CPU 보다 매우 느리기 때문에 입출력 작업의 완료를 CPU가 마냥 기다리는 것은 비효율적입니다. 따라서 입출력 장치가 처리를 수행하는 동안 CPU는 다른 작업을 수행하고 입출력 처리 종료 후 이를 CPU에게 알리기 위해 인터럽트를 사용합니다.
    인터럽트 이외에도 폴링 방식으로 입출력 작업의 완료 여부를 CPU가 인식할 수 있는데요. 폴링은 CPU가 주기적으로 입출력 장치의 상태를 검사하기 때문에 CPU의 작업 효율이 떨어지게 됩니다. 반면 인터럽트 방식을 사용할 경우에는 처리 종료 인터럽트를 받을 때까지 CPU는 다른 작업에 집중할 수 있어 더욱 효율적입니다.
    이외에도 예외 상황이 발생한 경우 인터럽트를 이용하여 장애를 신속하게 처리할 수 있으며 CPU의 즉각적인 처리로 사용자 응답성이 향상되고 정확한 타이밍을 제어할 수 있기 떄문에 인터럽트를 사용합니다.

</details>

<details>
    <summary>인터럽트의 발생 시 수행 과정을 말씀해주세요.</summary>
    <br/><code>요청</code> → <code>중단</code> → <code>보관</code> → <code>인터럽트 처리</code> → <code>재개</code><br/><br/>

    하드웨어나 소프트웨어에서 인터럽트 시그널을 CPU에게 보내면 CPU는 해당 인터럽트에 응답하기 전 현재 수행 중인 명령어까지 완료합니다. 그 후 대기 중인 인터럽트 요청이 있는지 확인하고 있을 경우 처리하던 프로세스에 대한 정보를 PCB에 저장합니다. 이후 인터럽트 벡터를 참고하여 인터럽트 처리 루틴 코드가 저장된 주소를 찾아내 해당 루틴을 실행합니다. 이후 처리가 완료되면 준비 상태의 프로세스의 PCB를 통해 인터럽트 발생 이전으로 복구시킨 후 프로세스 실행을 재개합니다.

</details>

<details>
    <summary>시스템 콜이 필요한 이유는 무엇인가요?</summary>
    <br/><code>응용 프로그램-하드웨어 자원 간 인터페이스</code><br/><br/>

    운영체제는 응용 프로그램이 하드웨어 자원에 직접 접근하는 것을 방지하여 자원을 보호합니다. 즉 응용 프로그램이 자원에 접근하기 위해서는 항상 운영체제를 통해서만 가능합니다.
    시스템 콜은 응용 프로그램이 운영체제의 커널이 제공하는 서비스를 통해 하드웨어 자원에 접근하기 위한 일종의 인터페이스인데요. 즉 응용 프로그램이 파일에 접근하거나 화면에 결과를 출력하는 등의 작업이 필요한 경우 운영체제에게 이러한 작업의 대행을 요청하는 것이라고 할 수 있습니다.
    이때 사용자 프로세스가 이러한 커널의 서비스를 제공받기 위해서는 CPU의 모드를 사용자 모드에서 커널 모드로 전환해야 하고 이는 시스템 콜을 통해 이루어집니다.

</details>

<details>
    <summary>CPU 모드의 2가지 종류인 사용자 모드와 커널 모드에 대해 설명해주세요.</summary>
    <br/><code>응용 프로그램</code>, <code>운영체제의 커널</code><br/><br/>

    먼저 CPU의 이중 모드란 CPU가 명령어를 실행하는 모드를 크게 사용자 모드와 커널 모드로 구분하는 방식입니다.
    사용자 모드는 운영체제 서비스를 제공받을 수 없는 실행 모드로, 즉 커널 영역의 코드를 실행할 수 없는 모드입니다. 일반적인 응용 프로그램은 기본적으로 사용자 모드로 실행되며 사용자 모드로 실행 중인 CPU는 하드웨어 자원에 접근하는 명령어를 실행할 수 없습니다. 따라서 사용자 모드로 실행 중인 프로세스가 자원에 접근하는 운영체제 서비스를 제공받으려면 시스템 콜을 호출하여 커널 모드로 전환되어야 합니다.
    커널 모드는 운영체제 서비스를 제공받을 수 있는 실행 모드로, 즉 커널 영역의 코드를 실행할 수 있는 모드입니다. CPU가 커널 모드로 명령어를 실행하면 자원에 접근하는 명령어를 비롯한 모든 명령어를 실행할 수 있습니다.

    참고로 CPU의 플래그 레지스터 속 슈퍼바이저 플래그가 0이면 사용자 모드로 1이면 커널 모드로 실행 중임을 나타냅니다.

    참고: https://post.naver.com/viewer/postView.naver?volumeNo=34569580&memberNo=25379965&vType=VERTICAL

</details>

<hr/>

<details>
    <summary>교착상태 회피 및 탐지 알고리즘 중 하나에 대해 자세히 설명해주세요.</summary>
    <br/>

    교착 상태가 발생하기 전에 교착 상태를 예상하여 안전한 상태(safe state)에서만 자원 요청을 허용하는 방법인 교착 상태 회피 알고리즘 중 자원 할당 그래프 알고리즘에 대해 설명드리겠습니다. 이 알고리즘은 자원 유형별로 인스턴스가 하나 있는 경우 교착상태를 회피할 수 있으며 프로세스 시작 전 각 프로세스와 자원을 노드로 하는 방향 그래프인 자원할당 그래프에 예약 간선을 표시하는데요. 여기서 예약 간선은 프로세스가 향후 요청할 수 있는 자원을 가리키는 점선으로 표시된 간선으로 프로세스는 예약 간선으로 설정한 자원에 대해서만 실제 요청이 가능하며 사이클이 형성되지 않을 때에만 자원 할당을 받습니다. 즉 프로세스 간 자원 할당 사이클이 발생하지 않도록 하여 교착상태를 피할 수 있습니다.

    그러나 프로세스 수가 고정되어야 함, 자원의 종류와 수가 고정되어야 함, 프로세스가 요구하는 자원 및 최대 자원 수를 알아야 함, 프로세스는 반드시 자원 사용 후 반납해야 함의 가정이 요구되기 때문에 현실적으로 불가능한 방법입니다.

    참고: https://yoongrammer.tistory.com/67

</details>

<details>
    <summary>교착 상태와 기아 상태에 간단히 설명해주시고 그 둘의 차이점에 대해 설명해주세요.</summary>
    <br/><code>프로세스 간 점유 자원 할당 요구</code>, <code>자원 할당 지연</code><br/><br/>

    교착 상태란 둘 이상의 프로세스가 서로가 가진 자원을 요구하면서 해당 프로세스들의 수행이 중단되는 상태를 의미합니다. 반면 기아 상태는 프로세스가 원하는 자원을 계속 할당 받지 못하는 상태로, 여러 프로세스가 부족한 자원을 두고 경쟁할 때 계속해서 우선순위에서 밀려나 오랫동안 실행되지 못하는 프로세스를 기아 상태에 있다고 말합니다.
    두 상태는 프로세스에게 필요한 자원이 할당되지 않아 프로세스가 더이상 실행되지 않는다는 점에서 비슷하지만, 교착 상태가 발생하면 둘 이상의 프로세스의 실행이 중단되고 이에 따라 교착 상태의 프로세스가 점점 증가할 수 있는 반면 기아 상태는 특정 프로세스만이 우선순위 등에 밀려 수행이 지연되는 것으로 즉 기아 상태가 다른 프로세스들에 영향을 주지는 않습니다.
    교착 상태는 적절한 조치를 취하지 않는 이상 상태가 영원히 지속될 수 있는 반면, 기아 상태는 해당 자원을 요청하는 프로세스가 줄어든다면 자동으로 기아 상태에서 벗어날 수도 있습니다.

</details>

<details>
    <summary>가상 메모리란 무엇인지와 장점에 대해 설명해주세요.</summary>
    <br/><code>프로세스 일부 적재</code>, <code>메모리 크기 제약↓</code>, <code>CPU 이용률과 처리량 증가</code><br/><br/>

    메모리의 크기는 한정되어 있기 때문에 물리적인 메모리 크기보다 큰 프로세스는 실행시킬 수 없는 문제를 해결하기 위해 등장.

    어떤 프로세스가 실행될 때 메모리에 해당 프로세스 전체가 올라가는 것이 아닌 현재 실행에 필요한 프로세스의 코드, 데이터의 일부만 적재되고 나머지는 보조기억장치에 저장하는 메모리 관리 기법 중 하나입니다. 즉 빠르고 작은 메모리와 크고 느린 디스크를 병합하여 하나의 크고 빠른 기억 장치처럼 동작하게 하는 기술입니다.

    따라서 프로세스의 실행이 메모리 크기의 제약으로부터 자유로워졌으며, 각 프로세스가 더 적은 메모리를 차지하여 더 많은 프로세스를 동시에 수행할 수 있어 CPU 이용률과 처리량이 증가한다는 장점이 있습니다.

    *MMU(Memory Management Unit): 특수 메모리 관리 하드웨어, 가상주소를 물리주소로 변환 + 메모리 보호 기능
    *TLB(Translation Lookaside Buffer, 페이지 정보 캐시): 가상주소를 물리주소로 변환하는 속도를 높이기 위해 사용하는 캐시, MMU에 포함된 작은 캐시로 일종의 주소 변환 캐시

</details>

<details>
    <summary>요구 페이징이란 무엇인지 장점과 함께 설명해주세요.</summary>
    <br/><code>페이지 일부 적재</code>, <code>메모리 크기 제약↓</code>, <code>CPU 이용률과 처리량 증가</code><br/><br/>

    프로세스를 페이지 단위로 나누고 실행에 필요한 부분과 필요없는 부분 중 당장 실행에 필요한 페이지만을 메모리에 적재하는 기법을 요구 페이징이라 합니다. 당장 실행에 필요없는 부분은 Backing Store 즉 보조기억장치에 저장해놓았다가 필요 시 메모리에 적재하는 식으로 동작합니다.

    요구 페이징은 필요한 페이지만 메모리에 적재하기 때문에 메모리 사용량이 감소하며 따라서 더 많은 프로세스를 동시에 수행할 수 있어 CPU 이용률과 처리량이 증가합니다. 또한 크기가 큰 디스크를 같이 사용함으로써 메모리의 물리적 크기 제약에서 벗어날 수 있습니다. 마지막으로 프로세스 전체를 메모리에 올리는데 소요되는 입출력 오버헤드가 감소한다는 장점이 있습니다.

    다중 프로그래밍의 정도가 과하거나, 잘못된 메모리 할당/페이지 교체 알고리즘을 사용하거나, 기본적으로 메모리양 적을 때 페이지 폴트가 빈번하게 발생하여 메모리 프레임에서 페이지가 반복적으로 교체되고 디스크 입출력이 증가하는 현상인 스래싱이 발생할 수 있다는 문제점이 있습니다. 이 경우 프로세스의 처리 시간보다 페이지 교체에 드는 시간이 증가하여 CPU 이용률이 감소할 수 있습니다.

    *페이지 테이블의 Valid-Invalid Bit: 페이지가 메모리에 적재되어 있는지 판단하기 위한 비트

</details>

<details>
    <summary>IPC란 무엇인지, 왜 프로세스에는 별도의 IPC 메커니즘이 필요한지에 대해 설명해주세요.</summary>
    <br/><code>프로세스 간 통신</code>, <code>프로세스 = 독립적인 실행 객체</code><br/><br/>

    하나의 프로그램을 실행하더라도 여러 프로세스 간 협력이 필요(협력적인 프로세스) → 이러한 협력 프로세스 간에 데이터를 주고 받는 행위를 IPC라고 정의합니다.
    그러나 프로세스는 독립된 실행 객체이기 때문에 프로세스 별로 독립된 자원이 할당되며 다른 프로세스 자원에 대한 접근은 운영체제에 의해 보호됩니다. 즉 프로세스 간에는 공유하고 있는 자원이 없기 때문에 별도의 IPC 매커니즘이 필요하게 됩니다. 따라서 운영체제 커널이 제공하는 별도의 IPC 설비를 이용해 프로세스 간 통신을 수행해야 합니다.

</details>

<details>
    <summary>여러 IPC 구현 모델 중 하나를 골라 자세히 설명해주세요.</summary>
    <br/><code>Shared Memory</code>, <code>Pipe</code>, <code>Message Queue</code>, <code>Socket</code><br/><br/>

    프로세스 간에 교환되는 메시지를 통해 데이터를 주고 받는 모델인 Message Passing의 예시 모델인 파이프에 대해 설명드리겠습니다. 먼저 파이프란 여러 프로세스가 공통으로 사용하는 임시 공간(파일)입니다. 파이프에는 입구와 출구가 고정되어 있어 데이터가 한 방향으로만 이동하여 프로세스 간 단방향 통신을 수행할 수 있습니다. 따라서 한 쪽 프로세스는 쓰기만 하고 다른 프로세스는 읽기만 하는 단순한 데이터 흐름에 적합한 모델입니다.

    이 파이프 모델은 익명성에 따라 다시 2가지로 나뉘게 됩니다. 먼저 익명 파이프는 일반적인 파이프 방식으로 주로 부모-자식 간의 단방향 통신에 사용되며 외부 프로세스와는 사용이 불가능합니다. 이는 파이프에 접근하기 위한 파일 디스크립터가 부모-자식 프로세스 간에만 공유가 가능하기 때문입니다.
    반면 서로 관련 없는 프로세스들 간의 통신을 위해서는 네임드 파이프를 이용할 수 있습니다. 이때에는 파일 디스크립터가 아닌 파이프의 이름을 통해 파이프에 접근하여 통신할 수 있습니다.

</details>

<details>
    <summary>캐시 메모리가 등장하게 된 이유를 설명해주세요.</summary>
    <br/><code>CPU 연산 속도</code>, <code>메모리 접근 속도</code><br/><br/>

    캐시 메모리란 CPU의 처리 속도와 주기억장치의 속도 차이를 줄이기 위해 사용하는 SRAM 기반의 고속 기억장치로 CPU와 메모리 사이에 위치해있으며 레지스터 보다는 느리고 메모리보다는 빠릅니다.

    CPU의 성능은 빠르게 향상된 반면 DRAM 즉 메모리의 성능 향상은 더디었습니다. 따라서 CPU의 빠른 속도를 메모리가 따라가지 못해 전체 시스템 성능이 저하되는 문제가 발생하였습니다. 이를 해결하고자 캐시 메모리를 두어 CPU의 연산 속도와 메모리 접근 속도의 차이를 줄이도록 하였습니다.

</details>

<details>
    <summary>캐시 메모리의 동작 과정에 대해 차례대로 설명해주세요.</summary>
    <br/><code>캐시 히트</code>, <code>캐시 미스</code>, <code>시간 지역성</code>, <code>공간 지역성</code><br/><br/>

    CPU가 메모리에서 직접 데이터를 요청하기 전 캐시 메모리에 접근하여 요청한 데이터의 존재 여부를 확인합니다. 해당 데이터가 캐시에 존재하는 경우를 캐시 히트라 지칭하며 이후 CPU는 반환된 데이터에 대한 처리를 수행합니다. 그러나 만약 해당 데이터가 캐시에 존재하지 않고 메모리에 있다면 이를 캐시 미스라 지칭하며 이 경우 CPU를 잠시 기다리게 한 후 메모리에서 해당 데이터를 읽어와 CPU에게 넘겨줍니다.
    이때 최근 접근한 데이터에 다시 접근하는 경향이 있다는 시간지역성에 근거하여 메모리에서 읽어온 데이터는 캐시에 적재하며, 또한 최근 접근한 데이터의 주변 데이터에 다시 접근하는 경향이 있다는 공간지역성에 근거하여 현재 읽어온 데이터뿐만 아니라 옆 주소의 데이터들도 같이 읽어와 캐시에 적재합니다.

</details>

<details>
    <summary>임계 영역이 무엇인지와, 임계 영역으로 인한 문제를 해결하기 위한 방법에 대해 설명해주세요.</summary>
    <br/><code>공유 자원 접근 코드</code>, <code>상호 배제</code>, <code>진행</code>, <code>유한 대기</code><br/><br/>

    임계 영역이란 동시에 접근하면 문제가 발생하는 공유 자원에 접근하는 코드 영역을 말합니다. 이 경우 프로세스 또는 스레드의 접근 순서에 따라 결과값이 달라지는 레이스 컨디션이 발생할 수 있습니다.
    이 문제를 해결하기 위해서는 상호 배제, 진행, 유한 대기의 조건을 만족시켜야 하는데요. 먼저 상호 배제는 한 프로세스가 임계 영역에 진입했다면 다른 프로세스는 들어올 수 없음을, 진행은 임계 영역에 들어간 프로세스가 없는 상태에서 들어가고자 하는 프로세스가 여러 개라면 어느 것이 진입할지 결정해주는 것을, 유한 대기는 임계 영역에 진입하기 위해 대기하는 모든 프로세스는 유한 시간 내에는 해당 영역으로 진입할 수 있어야 함을, 즉 무한정 대기해서는 안된다는 것을 (기아 상태 방지 위해) 의미합니다.

    이를 위한 구체적인 해결책으로는 Mutex, Semaphore가 있습니다.

    *동기화: 공유 자원에 동시에 접근하지 못하도록 접근 순서를 제어하는 방법 (프로세스/스레드 간 동기화는 일반적으로 상호 배제를 통해 구현)

</details>

<details>
    <summary>뮤텍스와 세마포어의 차이점에 대해 설명해주세요.</summary>
    <br/><code>잠금 기반/신호 기반</code>, <code>공유 자원 접근 프로세스, 스레드 개수</code>, <code>해제 주체</code><br/><br/>

    뮤텍스는 공유 자원을 사용하기 전에 Lock을 걸고 사용한 후에는 Lock을 해제하는 잠금 매커니즘인 반면 세마포어는 임계 영역에 진입할 수 있는 프로세스 혹은 스레드의 개수로 정의되는 정수를 두어 공유 자원을 사용하기 전에는 정수값 -1(wait(), P)을 사용한 후에는 정수값 +1(signal(), V) 연산을 수행하는 신호 기반의 상호 배제 방법입니다.
    세마포어는 카운팅 세마포어를 사용하면 세마포어 정수 크기 만큼의 프로세스, 스레드들이 공유 자원에 접근할 수 있는 반면 뮤텍스는 오직 1개의 프로세스, 스레드만이 공유 자원에 접근할 수 있습니다. (공유 자원이 여러 개이더라도? ex. 화장실이 2개 이상이더라도)
    또한 세마포어는 현재 수행 중인 프로세스가 아닌 다른 프로세스가 해제할 수 있지만 뮤텍스는 반드시 락을 획득한 프로세스가 다시 락을 해제해야 합니다.

    뮤텍스에서는 사용 가능한 공유 자원에 잠금을 검 → 잠금이 설정된 자원에 다른 프로세스나 스레드는 접근 불가 → 공유 자원 사용 후 임계 영역에서 벗어날 때 잠금 해제 → 다른 프로세스나 스레드 해당 자원에 접근 가능

    세마포어에서는 공유 자원 접근 시 wait 연산 수행 → 세마포어 정수값을 1 감소 → 만약 감소된 세마포어 정수가 음수라면 해당 프로세스는 세마포어 대기열에서 대기 → 공유 자원 사용 후 임계 영역에서 벗어날 때 signal 연산 수행 → 세마포어 정수값을 1 증가 → 세마포어 대기열에서 대기 중인 프로세스 중 하나를 깨워 임계 영역에 진입할 수 있도록 함

    참고: https://medium.com/@kwoncharles/%EB%AE%A4%ED%85%8D%EC%8A%A4-mutex-%EC%99%80-%EC%84%B8%EB%A7%88%ED%8F%AC%EC%96%B4-semaphore-%EC%9D%98-%EC%B0%A8%EC%9D%B4-de6078d3c453

</details>
