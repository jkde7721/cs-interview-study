## 네트워크 면접 질문 리스트

<details>
    <summary>TCP와 UDP의 차이를 설명해주세요.</summary>
    <br/>
    <table>
    <tr><th>TCP(Transfer Control Protocol)</th><th>UDP(User Datagram Protocol)</th></tr>
    <tr><td>연결이 성공해야 통신 가능(연결형 프로토콜)</td><td>연결 없이 통신 가능(비연결형 프로토콜)</td></tr>
    <tr><td>데이터의 경계 구분X(Byte-Stream Service)</td><td>데이터의 경계 구분O(Datagram Service)</td></tr>
    <tr><td>신뢰성 있는 데이터 전송(데이터 재전송)</td><td>비신뢰성의 데이터 전송</td></tr>
    <tr><td>일대일(Unicast) 통신</td><td>일대일, 일대다(Broadcast), 다대다(Multicast) 통신</td></tr>
    </table>

    TCP는 연결지향형 프로토콜로 신뢰성 있는 데이터 전송을 보장하기 위해 혼잡제어, 흐름제어 등의 기능을 제공합니다. 이러한 부가적인 제어 기능과 통신을 위한 초기 연결 설정으로 인해 데이터 전송 속도가 UDP에 비해 상대적으로 느립니다. 그러나 안정적이기 때문에 빠른 속도 보다 데이터의 정확성이 중요한 일반적인 어플리케이션에서 많이 사용됩니다.

    반대로 UDP는 비연결지향형 프로토콜로 혼잡제어, 흐름제어를 지원하지 않고 체크섬 필드를 기반으로 간단한 오류 검사 기능만을 제공합니다. 따라서 데이터 전송 여부와 순서가 보장되지 않아 TCP에 비해 비신뢰적인 프로토콜입니다. 그러나 데이터를 더 빠르게 전송할 수 있어 데이터의 정확성 보다는 전송 속도가 중요한 실시간 동영상 서비스 등 멀티 미디어 전송에 UDP를 사용할 수 있습니다.

</details>

<details>
    <summary>TCP와 UDP는 각각 어떤 상황에서 쓰는게 바람직한가요?</summary>
    <br/><code>신뢰성</code> <code>고속성</code>

    TCP는 연결지향형 프로토콜로 데이터를 안정적으로 보낼 수 있다는 장점이 있습니다. 그러나 신뢰성 있는 데이터를 전송하기 위한 부가적인 제어와 초기 연결 설정 시간으로 데이터 전송 속도가 느리기 떄문에 빠른 속도 보다는 데이터의 신뢰성이 요구되는 일반적인 어플리케이션에서 주로 사용됩니다.

    반면 UDP는 비연결지향형 프로토콜로 데이터의 전송을 보장하지 않아 신뢰성은 떨어지지만 무엇보다 빠르게 전송할 수 있다는 장점이 있습니다. 따라서 데이터가 조금 깨져도 되지만 빠른 전송 속도가 중요한 경우 즉 신뢰성 보다는 고속성을 요구하는 멀티미디어 응용 등에서 일부 사용됩니다.

</details>

<details>
    <summary>TCP에서 제공하는 흐름제어와 혼잡제어에 대해서 설명해주세요.</summary>
    <br/><code>수신자의 버퍼 오버플로우</code> <code>윈도우</code> <code>ACK 패킷</code>

    흐름제어는 송신 측과 수신 측의 데이터 처리 속도 차이를 해결하기 위한 기법으로 데이터 처리 속도롤 조절하여 수신자의 버퍼 오버플로우를 방지합니다. 버퍼가 가득차게 되면 손실되는 패킷들이 발생하기 때문에 신뢰성 있는 데이터 전송을 위해서는 전송 속도를 조절하는 것은 매우 중요합니다. 이는 수신자가 윈도우 크기 값을 조절하여 수신량을 설정할 수 있습니다.

    네트워크 내에 패킷의 수가 과도하게 증가하는 현상이 발생한 경우 혼잡제어를 통해 네트워크 내의 패킷 수가 더이상 증가하지 않도록 방지할 수 있습니다. 수신 측으로부터 일정 시간 동안 ACK 패킷을 수신하지 못하였거나 수신 측으로부터 3번 이상 중복된 ACK 번호의 패킷을 받은 경우 등을 혼잡한 상황이라고 판단하여 수신 측으로 전송하는 패킷의 양을 줄일 수 있습니다.

</details>

<details>
    <summary>TCP와 IP의 차이에 대해 설명해주세요.</summary>
    <br/> <code>속도</code> <code>정확성</code>

    IP는 패킷을 지정한 IP 주소에 최대한 빨리 보내는 프로토콜로, 전송된 패킷의 순서가 바뀌거나 일부가 누락되더라도 상관하지 않고 일단 목적지로 빠르게 보내는 역할을 합니다.
    반면 TCP는 이러한 IP를 보강하는 프로토콜로, 도착한 패킷을 점검하여 순서가 다르거나 빠진 패킷이 있다면 다시 요청하는 식으로 정확한 데이터를 받을 수 있도록 합니다.

    정리해서 IP는 데이터의 정확성 보다는 속도에, TCP는 속도 보다는 데이터의 정확성에 주안점을 둔 프로토콜이라 할 수 있습니다.

</details>

<details>
    <summary>OSI 7계층과 TCP/IP 4계층의 차이점과 TCP/IP 4계층에서의 캡슐화와 역캡슐화에 대해 설명해주세요</summary>
    <br/><code>헤더 정보</code>
    
    OSI 7 계층은 네트워크 통신이 일어나는 과정을 7단계로 나눈 표준으로 이 표준을 TCP/IP 프로토콜 통신 과정에 초점을 맞춰 단순화한 계층이 TCP/IP 4계층입니다.

    TCP/IP 4계층의 캡슐화는 데이터 전송 시 상위 계층에서 하위 계층으로 이동하면서 각 계층에서 데이터에 헤더 정보가 추가되는 것을 말합니다. 반면 역캡슐화는 데이터 수신 시 데이터가 하위 계층에서 상위 계층으로 이동하면서 전송 시 추가되었던 헤더 정보를 읽고 알맞은 행동을 취한 후 해당 헤더를 제거해 상위 계층으로 전달해주는 것을 말합니다.

</details>

<details>
    <summary>OSI 7계층 정리</summary>

    네트워크 통신이 일어나는 과정을 7단계로 나눈 표준

    - 물리 계층: 데이터를 전기적인 신호로 변환해서 단순히 데이터를 주고 받기만 하는 기능 (단위: Bit)
    - 데이터 링크 계층: 데이터의 오류와 흐름을 관리하여 안전한 데이터 전달 가능(CRC 기반의 오류제어, 흐름제어), MAC 주소를 기반으로 point-to-point 간 신뢰성 있는 전송 (단위: Frame)
    - 네트워크 계층: 경로(Route)와 주소(IP)를 정하고 패킷을 전달, 최적의 경로를 설정하여 목적지까지 가장 안전하고 빠르게 데이터를 보냄 (전송단위: Packet/Datagram)
    - 전송 계층: 양 끝단의 사용자 간 신뢰성 있는 데이터를 주고 받게 함(오류검출 및 복구, 흐름제어와 중복검사 수행), Port 번호를 기반으로 데이터 전송 (전송단위: Segment)
    - 세션 계층: TCP/IP 세션을 만들고 없애는 역할
    - 표현 계층: 전송하는 데이터의 표현 방식 결정(ex. 데이터 변환, 압축, 암호화 등)
    - 응용 계층: 사용자와 가장 가까운 계층, 응용 서비스나 프로세스가 응용 계층에서 동작

</details>

<details>
    <summary>TCP/IP 4계층 정리</summary>

    OSI 7계층 이론을 실제 인터넷에 적용한 표준

    - 네트워크 엑세스 계층: OSI 7계층의 물리 + 데이터 링크 계층, Node-To-Node 간 신뢰성 있는 데이터 전송을 담당하는 계층
    - 인터넷 계층: OSI 7계층의 네트워크 계층, 패킷에 출발지와 목적지의 IP 주소를 첨부, 패킷 전달 여부를 보증하지 않고 가장 효율적인 경로를 설정하여 빠르게 패킷 전송
    - 전송 계층: OSI 7계층의 전송 계층, TCP/UDP를 담당하는 계층
    - 응용 계층: OSI 7계층의 5,6,7 계층, HTTP/FTP를 담당하는 계층, 서버나 클라이언트 응용 프로그램이 응용 계층에서 동작

</details>

<hr/>

<details>
    <summary>동기와 비동기(블로킹과 넌블로킹)의 차이와 장단점에 대해 설명해주세요.</summary>
    <br/><code>제어권</code> <code>병렬 수행</code> <code>순차적 흐름</code>

    블로킹, 넌블로킹은 전체 작업의 흐름 자체에 대한 block 여부에 따라 구분됩니다. 먼저 블로킹은 요청한 작업을 실행하는 프로세스가 작업을 요청한 프로세스에게 제어권을 넘겨주지 않아 작업을 모두 마칠 떄까지 현재 프로세스가 중지되는 방식으로 동작합니다. 반면 논블로킹은 작업을 요청한 프로세스에게 바로 제어권을 넘겨주어 다른 프로세스가 해당 작업을 실행하는 중에도 현재 프로세스가 동작할 수 있어 병렬 수행이 가능합니다.

    동기와 비동기는 요청한 작업의 완료 여부를 신경써서 작업을 순차적으로 수행할지 말지에 따라 구분됩니다. 쉽게 말해 동기는 여러 요청 작업을 순차적으로 처리하며, 비동기는 여러 요청 작업을 동시적으로 처리합니다. 즉 동기는 현재 작업이 완료되어야 다음 작업을 순차적으로 실행하는 반면, 비동기는 현재 작업의 완료 여부를 따지지 않고 바로 다음 작업을 수행하며 작업 요청 시 전달한 callback이 해당 작업 결과에 대한 후처리를 실행합니다.

</details>

<details>
    <summary>Synchronous & Blocking과 Asynchronous & Non-Blocking의 동작 방식과 어떤 상황에 적절한지 이유와 함께 설명해주세요.</summary>
    <br/><code>요청한 작업의 결과</code> <code>작업의 특성</code> <code>처리량</code>

    요청한 작업이 진행되는 동안 현재 작업을 처리하지 않고 요청한 작업의 완료 여부를 바로 받아 순차적으로 처리하는 방식입니다. 이는 요청한 작업의 결과가 현재 작업에 영향을 주는 경우 활용되는 방식입니다. 코드가 순차적으로 실행되는 특성으로 작업이 간단하거나 처리량이 적은 경우에 적절합니다. 만약 반대되는 상황에 동기 & 블로킹 방식을 채택한다면 한 작업이 끝날 때까지 다른 작업들은 처리가 불가능하여 전체적인 시스템 성능이 떨어지게 됩니다.

    요청한 작업이 진행되는 동안에도 현재 작업을 처리하고 요청한 작업의 결과를 바로 처리하지 않아 작업 순서가 지켜지지 않는 방식입니다. 요청한 작업의 결과가 현재 작업에 영향을 주지 않는 경우에 주로 활용되며 작업량이 많거나 시간이 오래 걸리는 I/O 관련 작업을 처리해야 하는 경우에 적합합니다. 따라서 대용량 데이터나 많은 요청을 처리하는 서비스에서 채택하는 방식입니다.

</details>

<details>
    <summary>대규모 트래픽에 대처할 수 있는 방법에 대해 설명해주세요.</summary>
    <br/><code>Scale-Up</code> <code>Scale-Out</code> <code>Load Balancing</code>

    대규모 트래픽에 대처하기 위해서는 일단 서버의 성능을 높여야 합니다. 이때 서버의 성능을 높이는 방법에는 2가지가 있습니다. 기존 하나의 서버 사양을 높이는 Scale-Up과 요청을 처리하는 서버의 개수를 늘려 대규모의 네트워크 트래픽을 분산 처리하는 Scale-Out이 있습니다. 이때 각 요청을 적절하게 분배하여 한 서버에 트래픽이 몰리지 않도록 하는 기술인 로드 밸런싱이 필요해지게 됩니다.

    로드 밸런싱을 트래픽을 여러 서버에 적절하게 분배하여 특정 서버의 부하를 덜어줄 뿐만 아니라 active한 서버에게만 요청을 전송하여 높은 가용성과 신뢰성을 보장해줍니다. 따라서 서비스의 중단 없이 서버를 추가하거나 뺄 수 있어 현재의 네트워크 트래픽에 따라 서버 용량을 보다 유연하게 조절할 수 있습니다.

</details>

<details>
    <summary>L4와 L7이 대표적인 로드밸런서로 많이 활용되는 이유에 대해 설명해주세요.</summary>
    <br/><code>포트 정보</code> <code>섬세한 로드밸런싱</code>

    L4부터는 포트 정보를 바탕으로 분산 처리하는 것이 가능하여 요청 정보에 따라 보다 섬세하게 트래픽을 분배할 수 있기 때문입니다. 따라서 한 대의 서버에 각각 다른 포트 번호를 부여하여 다수의 서버 프로그램을 운영하는 경우에는 L4 이상의 로드밸런서를 사용해야 합니다.

    L4 로드밸런서는 IP 주소나 포트 번호, MAC 주소, 전송 프로토콜과 같은 네트워크 계층이나 트랜스포트 계층의 정보를 바탕으로 부하를 분산합니다.
    L4 로드밸런싱 기법: 라운드 로빈, 가중 라운드 로빈, IP 해시, 최소 연결, 최소 응답 시간

    L7 로드밸런서는 HTTP 헤더, 쿠키, URL 등과 같은 애플리케이션 계층 정보를 바탕으로 부하를 분산합니다. 따라서 특정한 패턴을 가진 바이러스를 감지하거나 DoS/DDoS와 같은 비정상적인 트래픽을 필터링함으로써 네트워크를 보호할 수 있습니다.
    L7 로드밸런싱 기법: URL 스위칭 방식, 컨텍스트 스위칭 방식, 쿠키 지속성

</details>

<details>
    <summary>대칭키 암호화 기법과 공개키 암호화(A.K.A 비대칭키 암호화) 기법에 대한 각각의 설명과 장단점에 대해 말씀해주세요.</summary>
    <br/><code>대칭키</code> <code>공개키</code> <code>비밀키</code>

    대칭키 암호화는 암호화와 복호화에 같은 키 1개만을 사용하는 알고리즘입니다. 암호화 복호화에 같은 키를 사용하기 때문에 처리 속도가 빠른 반면, 암호화 통신을 하는 사용자들은 같은 대칭키를 공유해야 한다는 제약으로 인해 키 교환 문제가 발생할 수 있습니다. 다시 말해 키를 교환하는 과정에서 키가 탈취되면 암호화된 데이터의 기밀성이 깨질 수 있습니다. (기밀성 제공, but 무결성, 인증, 부인 방지 보장X)

    공개키 암호화는 암호화와 복호화에 사용하는 키를 분리한 알고리즘으로 모두에게 공유된 공개키와 자신만이 가지고 있는 비밀키 총 2가지 종류의 키가 존재합니다. 공개키 암호화에는 수신자의 공개키로 암호화하여 수신자만이 해당 암호문을 복호화할 수 있는 암호 모드 방식과, 송신자의 개인키로 암호화하여 누구나 해당 암호문을 복호화할 수 있으며 해당 암호문의 송신자를 인증해주는 인증 모드 방식이 있습니다.
    공개키 암호화는 암호 모드로 동작할 경우 수신자의 비밀키로만 복호화할 수 있어 대칭키 암호화에 비해 안전하며 키 분배 및 관리도 더 쉽습니다. 그러나 암호화와 복호화에 사용되는 키가 달라 연산이 매우 복잡하여 처리 속도가 더 느리다는 단점이 있습니다. (기밀성, 무결성, 인증, 부인 방지 제공)

</details>

<details>
    <summary>대칭키와 공개키 각각 어떤 경우에 사용하면 좋을지 말씀해주세요.</summary>
    <br/><code>처리 속도</code> <code>보안상 위험</code>

    대칭키는 처리 속도가 빨라 통신 속도가 중요하거나 덜 민감한 데이터를 처리하는 애플리케이션에서 주로 사용하며, 공개키는 대칭키 암호화에 비해 처리 속도가 느리기 떄문에 일반적인 요청 처리보다는 대칭키를 공유하기 위해 주로 사용됩니다. 이를 통해 대칭키 탈취에 대한 위험성을 줄일 수 있습니다.

</details>

<details>
    <summary>HTTP와 HTTPS의 차이점과 각각 어떤 경우에 사용하는 것이 적절한 지 설명해주세요.</summary>
    <br/><code>데이터 암호화</code> <code>대칭키, 공개키</code>

    HTTP는 클라이언트와 서버 간 통신을 위한 규약으로 인터넷에서 텍스트 기반의 데이터를 주고 받을 수 있는 프로토콜입니다. (클라이언트의 요청과 서버의 응답 방식으로 동작)
    HTTPS는 HTTP에 데이터 암호화가 추가된 프로토콜로 네트워크 상에서 제3자가 데이터를 가로채더라도 해당 정보를 볼 수 없습니다. 이때 서버와 클라이언트는 공개키 암호화 방식을 통해 대칭키를 공유하고 이후의 요청과 응답 데이터는 대칭키로 암호화되어 서로에게 전달됩니다.

    HTTP는 일반 텍스트 형태로 데이터를 교환하여 보안에 취약합니다. 따라서 민감한 데이터가 아닌 노출되어도 괜찮은 단순한 정보 조회만을 처리하는 경우에 적절합니다. 반면 HTTPS는 암호화된 형태로 데이터를 교환하기 때문에 HTTP에 비해 더 강화된 보안을 제공합니다. 따라서 개인 및 금융 정보와 같은 민감한 데이터를 처리하는 경우에 주로 사용되며 현재의 대부분의 웹 서비스는 HTTPS 프로토콜을 기반으로 동작합니다.

</details>
